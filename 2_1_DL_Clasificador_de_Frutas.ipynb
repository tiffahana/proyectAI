{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tiffahana/proyectAI/blob/main/2_1_DL_Clasificador_de_Frutas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnTLK4Cfchew"
      },
      "source": [
        "\n",
        "# **Redes Neuronales Convolucionales: teoría y aplicaciones**\n",
        "# Clasificación de frutas usando CNN (modelo extremo a extremo)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6eRGkX2che7"
      },
      "source": [
        "----\n",
        "\n",
        "## Resumen\n",
        "\n",
        "Con el fin de ilustrar el uso de algunas herramientas disponibles para desarrollar una CNN, se muestra la implementación de ejemplos para la clasificación de frutas y el control de calidad. Además, los mismos ejemplos se implementaron utilizando modelos conocidos previamente entrenados para ilustrar otra perspectiva de solución utilizando transferencia de aprendizaje.\n",
        "\n",
        "\n",
        "----\n",
        "\n",
        "## Descripción general\n",
        "\n",
        "En el ejemplo, se utiliza el conjunto de datos [Fruit-360](https://github.com/Horea94/Fruit-Images-Dataset), que contiene 82213 imágenes (100 × 100 píxeles) de frutas y verduras de 120 clases, ya subdivididas en conjuntos de entrenamiento y de prueba. Específicamente, se seleccionaron seis categorías del conjunto de datos (tres tipos de manzanas y peras): Apple Golden 1, Apple Pink Lady, Apple Red 1, Pear Red, Pear Williams y Pear Monster.\n",
        "\n",
        "Se diseña una CNN con una arquitectura bastante simple compuesta por la capa de entrada, tres capas convolucionales, una capa de aplanamiento, una capa completamente conectada y la capa de salida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsOpAfMRche_"
      },
      "source": [
        "##**¡¡Manos a la obra!!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOsmSNT2qrK6"
      },
      "source": [
        "import os \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t                                # for manipulating the directories\n",
        "import cv2 \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t                                # for image processing\n",
        "import random \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t                              # for shuffling\n",
        "import numpy as np \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t                            # for array manipulating and scientific computing\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "\n",
        "import tensorflow as tf \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t                          # for more details see: https://www.tensorflow.org/tutorials\n",
        "from tensorflow import keras \t\t\t\t\t\t\t\t\t\t\t\t\t\t                        # for more details see: https://www.tensorflow.org/guide/keras/overview\n",
        "\n",
        "from tensorflow.keras.models import Model \t\t\t\t\t\t\t\t                      # for more details see about Model class API: https://keras.io/models/model/\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D, Flatten, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\t\t\t\t       \t\t\t\t          # for categorical labels\n",
        "from tensorflow.keras import optimizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqJ2sNJSrOlK"
      },
      "source": [
        "# general parameters\n",
        "NAME = 'fruits-classifier'                                                      # name for the callback output\n",
        "base_dir = \"datasets/fruits-360/\"\t                                              # directory path of the fruit dataset, download from: https://github.com/Horea94/Fruit-Images-Dataset (Horea Muresan, Mihai Oltean, Fruit recognition from images using deep learning, Acta Univ. Sapientiae, Informatica Vol. 10, Issue 1, pp. 26-42, 2018.)\n",
        "CATEGORIES = [\"Apple Golden 1\",\"Apple Pink Lady\",\"Apple Red 1\",\"Pear Red\",\"Pear Williams\",\"Pear Monster\"] \t# we work with three classes of Apple and Pear\n",
        "class_names = CATEGORIES\n",
        "num_classes = 6\n",
        "img_size = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh0LSThro0Gh"
      },
      "source": [
        "!git clone https://github.com/Horea94/Fruit-Images-Dataset.git\n",
        "\n",
        "!ls\n",
        "\n",
        "base_dir = 'Fruit-Images-Dataset/'\n",
        "\n",
        "!ls Fruit-Images-Dataset/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls Fruit-Images-Dataset/Training/"
      ],
      "metadata": {
        "id": "qCEXosPhs64x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po1cSEw5wLBs"
      },
      "source": [
        "# Read training set\n",
        "train_images = []\n",
        "train_dir = os.path.join(base_dir, 'Training/')\t\t\t\t\t\t\t\t\t\t              # set the training directory in the path\n",
        "\n",
        "for category in CATEGORIES:\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t                        # iterate to each category\n",
        "    path = os.path.join(train_dir, category)\n",
        "    class_num = CATEGORIES.index(category)\n",
        "    for image in os.listdir(path):\t\t\t\t\t\t\t\t\t\t\t\t\t                    # iterate to each image in the category\n",
        "        if(image.endswith('jpg') and not image.startswith('.')):\n",
        "            img_array = cv2.imread(os.path.join(path,image),                    # read the image\n",
        "                              cv2.IMREAD_GRAYSCALE)\n",
        "            train_images.append([img_array, class_num])\t\t\t\t\t\t\t\t          # save the image in training data array\n",
        "\n",
        "print(\"Training images: \", len(train_images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aA0-qOBY4soK"
      },
      "source": [
        "import random\n",
        "img_idx = random.sample(range(len(train_images)), 25)\n",
        "img_idx = np.array(img_idx)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[img_idx[i]][0], cmap='gray')\n",
        "    plt.xlabel(class_names[train_images[img_idx[i]][1]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrTVK8-xz_if"
      },
      "source": [
        "# Read testing set\n",
        "test_images = []\n",
        "test_dir = os.path.join(base_dir, 'Test/')\t\t\t\t\t\t\t\t\t\t\t                # set the test directory in the path\n",
        "\n",
        "for category in CATEGORIES:\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t                        # iterate to each category\n",
        "    path = os.path.join(test_dir, category)\n",
        "    class_num = CATEGORIES.index(category)\n",
        "    for image in os.listdir(path):\t\t\t\t\t\t\t\t\t\t\t\t\t                    # iterate to each image in the category\n",
        "        if(image.endswith('jpg') and not image.startswith('.')):\n",
        "            img_array = cv2.imread(os.path.join(path,image),                    # read the image\n",
        "                                   cv2.IMREAD_GRAYSCALE)\n",
        "            test_images.append([img_array, class_num])\t\t\t\t\t\t\t\t          # save the image in test data array\n",
        "\n",
        "print(\"Testing images: \", len(test_images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8z8HFYK9bbR"
      },
      "source": [
        "import random\n",
        "img_idx = random.sample(range(len(test_images)), 25)\n",
        "img_idx = np.array(img_idx)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(test_images[img_idx[i]][0], cmap='gray')\n",
        "    plt.xlabel(class_names[test_images[img_idx[i]][1]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Caa3KePV0Op3"
      },
      "source": [
        "# Shuffle the dataset before training for better accuracy\n",
        "x_train = []\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t                                # array for images\n",
        "y_train = []\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t                                # array for labels\n",
        "\n",
        "random.shuffle(train_images)\t\t\t\t\t\t\t\t\t\t\t\t\t\t                        # shuffle training images\n",
        "\n",
        "for features, label in train_images: \t\t\t\t\t\t\t\t\t\t\t\t                    # iterate to each image and the corresponding label in training data\n",
        "\tx_train.append(features)\n",
        "\ty_train.append(label)\n",
        "x_train = np.array(x_train)\n",
        "\n",
        "x_test = []\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t                                # array for images\n",
        "y_test = []\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t                                # array for labels\n",
        "\n",
        "random.shuffle(test_images) \t\t\t\t\t\t\t\t\t\t\t\t\t\t                        # shuffle testing images\n",
        "\n",
        "for features, label in test_images: \t\t\t\t\t\t\t\t\t\t\t\t                    # iterate to each image and the corresponding label in training data\n",
        "\tx_test.append(features)\n",
        "\ty_test.append(label)\n",
        "x_test = np.array(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8D6tqlPx0nPP"
      },
      "source": [
        "# reshape and normalize the data before training\n",
        "x_train = x_train.reshape(-1, img_size, img_size, 1)\n",
        "mean_train = np.mean(x_train, axis=0)\n",
        "x_train = x_train-mean_train\n",
        "x_train = x_train/255\n",
        "\n",
        "x_test = x_test.reshape(-1, img_size, img_size, 1)\n",
        "mean_test = np.mean(x_test, axis=0)\n",
        "x_test = x_test-mean_test\n",
        "x_test = x_test/255\n",
        "\n",
        "y_train = np.asarray(y_train)\n",
        "y_test = np.asarray(y_test)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ5fjbTY0y7W"
      },
      "source": [
        "# Hyperparameters settings\n",
        "input_shape = x_train.shape[1:]\n",
        "filters_numbers = [16, 32, 64]\n",
        "filters_size = [[5,5],[4,4],[3,3]]\n",
        "\n",
        "pool_size=(2, 2)\n",
        "weight_decay = 5e-4\n",
        "dropout = 0.6\n",
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "L2_norm = keras.regularizers.l2(weight_decay)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hT6-hAv71Eyk"
      },
      "source": [
        "# Setup model layers\n",
        "\n",
        "# Input layer\n",
        "model_input = Input(shape=input_shape)\n",
        "\n",
        "# 1st Convolutional layer\n",
        "model_output = Conv2D(filters_numbers[0], kernel_size=(filters_size[0]), kernel_regularizer=L2_norm, padding=\"Same\",\n",
        "\t\t\t\t\t\t\tactivation='relu', data_format='channels_last')(model_input)\n",
        "\n",
        "model_output = BatchNormalization()(model_output)\n",
        "\n",
        "model_output = MaxPooling2D(pool_size=(pool_size))(model_output)\n",
        "\n",
        "# 2nd Convolutional layer\n",
        "model_output = Conv2D(filters_numbers[1], kernel_size=(filters_size[1]), kernel_regularizer=L2_norm, padding=\"Same\",\n",
        "\t\t\t\t\t\t\tactivation='relu', data_format='channels_last')(model_output)\n",
        "\n",
        "model_output = BatchNormalization()(model_output)\n",
        "\n",
        "model_output = MaxPooling2D(pool_size=(pool_size))(model_output)\n",
        "\n",
        "# 3rd Convolutional layer\n",
        "model_output = Conv2D(filters_numbers[2], kernel_size=(filters_size[2]), kernel_regularizer=L2_norm, padding=\"Same\",\n",
        "\t\t\t\t\t\t\tactivation='relu', data_format='channels_last')(model_output)\n",
        "\n",
        "model_output = BatchNormalization()(model_output)\n",
        "\n",
        "model_ouput = GlobalAveragePooling2D(data_format='channels_last')(model_output)\n",
        "\n",
        "# Convert features to flatten vector\n",
        "model_output = Flatten()(model_output)\n",
        "\n",
        "# Full-connected layer\n",
        "model_output = Dense(512)(model_output)\n",
        "model_output = Dropout(dropout)(model_output)\n",
        "\n",
        "# Output layer\n",
        "model_output = Dense(num_classes, activation='softmax', name='id')(model_output)\n",
        "\n",
        "# Create the Model by using Input and Output layers\n",
        "model = Model(inputs=model_input, outputs=model_output, name=NAME)\n",
        "\n",
        "# Show the Model summary information\n",
        "model.summary()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=optimizers.SGD(lr, momentum), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40z5GlUu1WnD"
      },
      "source": [
        "# Train the model\n",
        "print(\"[INFO] Train the model on training data\")\n",
        "\n",
        "history = model.fit(x=x_train, y=np.asarray(y_train), batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0eGX0er1iCo"
      },
      "source": [
        "# Plot training curves\n",
        "x = [1,2,3,4,5,6,7,8,9,10]\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(x)\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.grid(b=None, which='major', axis='both')\n",
        "plt.savefig('fruits_classifier-training_acc.png')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(x)\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.grid(b=None, which='major', axis='both')\n",
        "\n",
        "plt.savefig('fruits_classifier-training_loss.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsmmVVfv1lZ-"
      },
      "source": [
        "# Test the model\n",
        "print(\"[INFO] Evaluate the test data\")\n",
        "\n",
        "results = model.evaluate(x=x_test, y=y_test, batch_size=batch_size, verbose=1)\n",
        "print('Testing Loss, Testing Acc: ', [round(r,4) for r in results])\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print('Accuracy', round(accuracy_score(y_test, y_pred),4))\n",
        "print('Classification report', classification_report(y_test, y_pred, target_names=class_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uv90UPJOUouP"
      },
      "source": [
        "Ejemplos de mapas de activación de la tercera capa de convolución:\n",
        "\n",
        "![CNN-architecture](https://drive.google.com/uc?id=1tx8PouEyoYM6mN1CM-vhsvGUNgu_i6fI)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3e0eEVg1xRe"
      },
      "source": [
        "# Plot Testing confusion matrix\n",
        "cmat = confusion_matrix(np.asarray(y_test), y_pred, normalize='true')\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cmat, display_labels=class_names)\n",
        "disp.plot(cmap='Blues', xticks_rotation='vertical', values_format='.2f')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}